// â”€â”€ DOM Refs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const loadingPanel = document.getElementById('loadingPanel');
const progressBar = document.getElementById('progressBar');
const loadPct = document.getElementById('loadPct');
const etaText = document.getElementById('etaText');
const statusBox = document.getElementById('statusBox');
const transcriptText = document.getElementById('transcriptText');
const translationText = document.getElementById('translationText');
const recordBtn = document.getElementById('recordBtn');

// â”€â”€ Loading State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Weights: whisper=~40 MB, marian=~75 MB, tts=~150 MB â†’ total ~265 MB
const MODEL_WEIGHTS = { whisper: 40, marian: 75, tts: 150 };
const TOTAL_MB = Object.values(MODEL_WEIGHTS).reduce((a, b) => a + b, 0);

// currentPct[model] = 0..100
const currentPct = { whisper: 0, marian: 0, tts: 0 };
// which model is active
let activeModel = null;
let loadStart = Date.now();

function updateOverallProgress() {
    // Weighted average of each model's progress contribution
    const done = Object.entries(currentPct).reduce((acc, [k, p]) => {
        return acc + (p / 100) * MODEL_WEIGHTS[k];
    }, 0);
    const overall = Math.round((done / TOTAL_MB) * 100);
    progressBar.style.width = overall + '%';
    loadPct.textContent = overall + '%';

    // ETA estimate
    const elapsed = (Date.now() - loadStart) / 1000; // seconds
    if (elapsed > 3 && overall > 2) {
        const totalEstSec = (elapsed / overall) * 100;
        const remaining = Math.round(totalEstSec - elapsed);
        if (remaining > 0) {
            const mins = Math.floor(remaining / 60);
            const secs = remaining % 60;
            const etaStr = mins > 0 ? `~${mins}m ${secs}s remaining` : `~${secs}s remaining`;
            etaText.textContent = `Downloading modelsâ€¦ ${etaStr}`;
        } else {
            etaText.textContent = 'Almost done â€” finalizingâ€¦';
        }
    }
}

function setStepState(model, state) {
    // state: 'pending' | 'active' | 'done'
    const row = document.getElementById(`step-${model}`);
    if (!row) return;

    // Clear classes
    row.classList.remove('active', 'done');

    // Remove old spinner/check/dot
    const old = row.querySelector('.step-spin, .step-check, .step-dot');
    if (old) old.remove();

    if (state === 'active') {
        row.classList.add('active');
        const spin = document.createElement('span');
        spin.className = 'step-spin';
        row.appendChild(spin);
    } else if (state === 'done') {
        row.classList.add('done');
        const check = document.createElement('span');
        check.className = 'step-check';
        check.textContent = 'âœ“';
        row.appendChild(check);
    } else {
        // pending
        const dot = document.createElement('span');
        dot.className = 'step-dot';
        row.appendChild(dot);
    }
}

// â”€â”€ Audio State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
let audioContext;
let mediaStream;
let processor;
let audioSegments = [];
let isRecording = false;

// â”€â”€ Worker â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const worker = new Worker('worker.js');

worker.addEventListener('message', event => {
    const data = event.data;

    // â”€â”€ Loading Phase Events â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if (data.status === 'load_start') {
        activeModel = data.model;
        setStepState(data.model, 'active');
        const names = { whisper: 'Whisper STT', marian: 'MarianMT Translator', tts: 'SpeechT5 TTS' };
        etaText.textContent = `Loading ${names[data.model] || data.model}â€¦`;

    } else if (data.status === 'model_progress') {
        currentPct[data.model] = data.pct;
        updateOverallProgress();

    } else if (data.status === 'model_done') {
        currentPct[data.model] = 100;
        setStepState(data.model, 'done');
        updateOverallProgress();

    } else if (data.status === 'init_done') {
        // All 3 models ready
        currentPct.whisper = 100;
        currentPct.marian = 100;
        currentPct.tts = 100;
        progressBar.style.width = '100%';
        loadPct.textContent = '100%';
        setStepState('whisper', 'done');
        setStepState('marian', 'done');
        setStepState('tts', 'done');
        etaText.textContent = 'âœ… All models cached â€” works offline now!';

        // Transition UI after a short pause
        setTimeout(() => {
            loadingPanel.style.display = 'none';
            statusBox.style.display = 'flex';
            statusBox.className = 'ready';
            statusBox.textContent = 'âœ… Ready! Hold to Speak.';
            recordBtn.disabled = false;
            recordBtn.textContent = 'ðŸŽ™ Hold to Speak';
        }, 800);

        // â”€â”€ Inference Phase Events â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    } else if (data.status === 'transcribing') {
        setStatus('busy', 'ðŸŽ™ Processing speech on Arm CPUâ€¦');
        transcriptText.textContent = 'Analysing audioâ€¦';
        transcriptText.style.color = '#ffc107';

    } else if (data.status === 'transcribed') {
        transcriptText.textContent = data.text;
        transcriptText.style.color = '#fff';

    } else if (data.status === 'translating') {
        setStatus('busy', 'ðŸŒ Running NMT translationâ€¦');
        translationText.textContent = 'Generating translationâ€¦';
        translationText.style.color = '#ffc107';

    } else if (data.status === 'translated') {
        translationText.textContent = data.text;
        translationText.style.color = '#fff';

    } else if (data.status === 'synthesizing') {
        setStatus('busy', 'ðŸ”Š Running TTS vocoderâ€¦');

    } else if (data.status === 'audio_ready') {
        setStatus('ready', 'âœ… Ready! Hold to Speak.');
        recordBtn.disabled = false;
        recordBtn.textContent = 'ðŸŽ™ Hold to Speak';

        const buf = audioContext.createBuffer(1, data.audio.length, 16000);
        buf.getChannelData(0).set(data.audio);
        const src = audioContext.createBufferSource();
        src.buffer = buf;
        src.connect(audioContext.destination);
        src.start();

    } else if (data.status === 'error') {
        // Show error in both panels
        etaText.textContent = 'âŒ ' + data.message;
        setStatus('error', 'âŒ ' + data.message);
        recordBtn.disabled = false;
        recordBtn.textContent = 'ðŸŽ™ Hold to Speak';
    }
});

function setStatus(cls, msg) {
    statusBox.className = cls;
    statusBox.textContent = msg;
}

// â”€â”€ Recording â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const startRecording = async () => {
    if (isRecording) return;
    isRecording = true;
    audioSegments = [];

    recordBtn.classList.add('pulse');
    recordBtn.textContent = 'ðŸ”´ Listeningâ€¦';
    transcriptText.textContent = 'Listening to microphoneâ€¦';
    transcriptText.style.color = '#aab0c0';
    translationText.textContent = 'Waiting for pipelineâ€¦';
    translationText.style.color = '#aab0c0';

    try {
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });

        const source = audioContext.createMediaStreamSource(mediaStream);
        processor = audioContext.createScriptProcessor(4096, 1, 1);

        processor.onaudioprocess = (e) => {
            audioSegments.push(new Float32Array(e.inputBuffer.getChannelData(0)));
        };

        source.connect(processor);
        processor.connect(audioContext.destination);
    } catch (e) {
        alert('Microphone permission denied or unsupported in this browser.');
        isRecording = false;
        recordBtn.classList.remove('pulse');
        recordBtn.textContent = 'ðŸŽ™ Hold to Speak';
    }
};

const stopRecording = () => {
    if (!isRecording) return;
    isRecording = false;

    recordBtn.classList.remove('pulse');
    recordBtn.textContent = 'Processingâ€¦';
    recordBtn.disabled = true;

    processor.disconnect();
    mediaStream.getTracks().forEach(t => t.stop());

    // Flatten all captured PCM chunks
    const totalLen = audioSegments.reduce((a, b) => a + b.length, 0);
    const flat = new Float32Array(totalLen);
    let offset = 0;
    for (const seg of audioSegments) { flat.set(seg, offset); offset += seg.length; }

    worker.postMessage({ type: 'process_audio', audio: flat });
};

// â”€â”€ Input Bindings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
recordBtn.addEventListener('mousedown', startRecording);
recordBtn.addEventListener('mouseup', stopRecording);
recordBtn.addEventListener('mouseleave', () => { if (isRecording) stopRecording(); });
recordBtn.addEventListener('touchstart', (e) => { e.preventDefault(); startRecording(); });
recordBtn.addEventListener('touchend', (e) => { e.preventDefault(); stopRecording(); });
